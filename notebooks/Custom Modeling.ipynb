{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dataiku\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import warnings\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from dataikuapi.dss.ml import DSSPredictionMLTaskSettings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace these constants by your own values\n",
        "EXPERIMENT_TRACKING_FOLDER_NAME = \"tracking\"\n",
        "EXPERIMENT_TRACKING_FOLDER_CONNECTION = \"dataiku-managed-storage\"\n",
        "EXPERIMENT_NAME = \"custom-modeling\"\n",
        "\n",
        "MLFLOW_CODE_ENV_NAME = \"mlflow\"\n",
        "SAVED_MODEL_NAME = \"custom-model\"\n",
        "DATASET_TRAINING = \"modeling_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Some utils\n",
        "def now_str() -> str:\n",
        "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment tracking (scikit-learn)\n",
        "\n",
        "This notebook contains a simple example to showcase the new Experiment Tracking capabilities of Dataiku. It explains how to perform several runs with different parameters, select the best run and promote it as a Saved Model version in a Dataiku Flow. It leverages:\n",
        "* the scikit-learn package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the training data\n",
        "\n",
        "Our training data lives in the `labeled` Dataset, let's load it in a pandas DataFrame and see what it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataiku.set_remote_dss('REPLACE_WITH_INSTANCE_URL', \n",
        "                       'REPLACE_WITH_YOUR_PROJECT_API_KEY',\n",
        "                      no_check_certificate=True)\n",
        "\n",
        "\n",
        "client = dataiku.api_client()\n",
        "client._session.verify = False\n",
        "project = client.get_default_project()\n",
        "training_dataset = dataiku.Dataset(DATASET_TRAINING)\n",
        "df = training_dataset.get_dataframe()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are working on a *binary classification* problem here, which is to predict whether or not a given customer is high value. This outcome is reflected by the `high_value` column which can either take the \"0.0\" or \"1.0\" values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_name = \"added_product\"\n",
        "target = df[target_name]\n",
        "data = df.drop(columns=[target_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get-or-create Managed Folder (WIP)\n",
        "project_folders = project.list_managed_folders()\n",
        "folder = None\n",
        "if len(project_folders) > 0:\n",
        "    for mf in project_folders:\n",
        "        if mf[\"name\"] == EXPERIMENT_TRACKING_FOLDER_NAME:\n",
        "            folder_id = mf[\"id\"]\n",
        "            print(f\"Found experiment tracking folder {EXPERIMENT_TRACKING_FOLDER_NAME} with id {mf['id']}\")\n",
        "            folder = project.get_managed_folder(odb_id=folder_id)\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "    # -- If you reach this point, you didn't find the experiment tracking folder among the existing ones.\n",
        "    if not folder:\n",
        "        print(\"Experiment tracking folder not found. Creating it...\")\n",
        "        folder = project.create_managed_folder(EXPERIMENT_TRACKING_FOLDER_NAME,\n",
        "                                   connection_name=EXPERIMENT_TRACKING_FOLDER_CONNECTION)\n",
        "else:\n",
        "    print(\"No folder found in project. Creating one for experiment tracking...\")\n",
        "    # Write the creation of the mf code here.\n",
        "    folder = project.create_managed_folder(EXPERIMENT_TRACKING_FOLDER_NAME,\n",
        "                                       connection_name=EXPERIMENT_TRACKING_FOLDER_CONNECTION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the experiment\n",
        "\n",
        "To prepare the grounds for our experiments, we need to create a few handles and define which MLFlow experiment we'll collect our runs into:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a mlflow_extension object to easily collect information for the promotion step\n",
        "mlflow_extension = project.get_mlflow_extension()\n",
        "\n",
        "# Create a handle for the mlflow client\n",
        "mlflow_handle = project.setup_mlflow(managed_folder=folder)\n",
        "\n",
        "# Set the experiment\n",
        "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimenting\n",
        "\n",
        "The goal of experiment tracking is to *instrument the iterative process of ML model training* by collecting all parameters and results of each trial. To be more specific, within an **experiment**, you perform multiple **runs**, each run being different from the others because of the **parameters** you use for it. You also need to specific which **metrics** to track, they will reflect the performance of the model for a given set of parameters.\n",
        "\n",
        "In this notebook example, if you want to produce experiment runs:\n",
        "* edit the parameters in the 3.1 cell and run it\n",
        "* run the 3.2 cell to effectively... perform the run ðŸ™‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining the parameters of our run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create run name\n",
        "run_params = {}\n",
        "run_metrics = {}\n",
        "\n",
        "# Define run parameters\n",
        "# -- Which columns to retain ?\n",
        "categorical_cols = [\"customer_relation_type_eom\", \"acquisition_channel\", \"customer_segment\"]\n",
        "run_params[\"categorical_cols\"] = categorical_cols\n",
        "numerical_cols = [\"age\", \"3m_nb_products_max\", \"months_customer\"]\n",
        "run_params[\"numerical_cols\"] = numerical_cols\n",
        "\n",
        "# --Which algorithm to use? Which hyperparameters for this algo to try?\n",
        "# ---Example: Gradient Boosting\n",
        "hparams = {\"n_estimators\": 300,\n",
        "          \"loss\": \"exponential\",\n",
        "          \"learning_rate\": 0.1,\n",
        "          \"max_depth\": 3,\n",
        "          \"random_state\": 42}\n",
        "clf = GradientBoostingClassifier(**hparams)\n",
        "model_algo = type(clf).__name__\n",
        "run_params[\"model_algo\"] = model_algo\n",
        "for hp in hparams.keys():\n",
        "    run_params[hp] = hparams[hp]\n",
        "\n",
        "# --Which cross-validation settings to use?\n",
        "n_cv_folds = 5\n",
        "cv = StratifiedKFold(n_splits=n_cv_folds)\n",
        "run_params[\"n_cv_folds\"] = n_cv_folds\n",
        "metrics = [\"f1_macro\", \"roc_auc\"]\n",
        "\n",
        "# --Let's print all of that to get a recap:\n",
        "print(f\"Parameters to log:\\n {run_params}\")\n",
        "print(100*'-')\n",
        "print(f\"Metrics to log:\\n {metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performing the run and logging parameters, metrics and the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_ts = now_str()\n",
        "run_name = f\"run-{run_ts}\"\n",
        "with mlflow.start_run(run_name=run_name) as run:\n",
        "    run_id = run.info.run_id\n",
        "    print(f\"Starting run {run_name} (id: {run_id})...\")\n",
        "    # --Preprocessing\n",
        "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('categorical', categorical_preprocessor, categorical_cols),\n",
        "        ('numerical', 'passthrough', numerical_cols)])\n",
        "    \n",
        "    # --Pipeline definition (preprocessing + model)\n",
        "    pipeline = make_pipeline(preprocessor, clf)\n",
        "    \n",
        "    # --Cross-validation\n",
        "    print(f\"Running cross-validation...\")\n",
        "    scores = cross_validate(pipeline, data, target, cv=cv, scoring=metrics)\n",
        "    for m in [f\"test_{mname}\" for mname in metrics]:\n",
        "        run_metrics[f\"mean_{m}\"] = scores[m].mean()\n",
        "        run_metrics[f\"std_{m}\"] = scores[m].std()\n",
        "        \n",
        "    # --Pipeline fit\n",
        "    pipeline.fit(X=data, y=target)\n",
        "    # --Log the order of the class label\n",
        "    run_params[\"class_labels\"] = [str(c) for c in pipeline.classes_.tolist()]\n",
        "    \n",
        "    # --Log parameters, metrics and model\n",
        "    mlflow.log_params(params=run_params)\n",
        "    mlflow.log_metrics(metrics=run_metrics)\n",
        "    artifact_path = f\"{model_algo}-{run_id}\"\n",
        "    mlflow.sklearn.log_model(sk_model=pipeline, artifact_path=artifact_path)\n",
        "    \n",
        "    # --Set useful information to faciliate run promotion\n",
        "    mlflow_extension.set_run_inference_info(run_id=run_id,\n",
        "                                            prediction_type=\"BINARY_CLASSIFICATION\",\n",
        "                                            classes=run_params[\"class_labels\"],\n",
        "                                            code_env_name=MLFLOW_CODE_ENV_NAME,\n",
        "                                            target=\"added_product\")\n",
        "    print(f\"DONE! Your artifacts are available at {run.info.artifact_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "analyzedDataset": "train",
    "createdOn": 1666967089230,
    "creator": "tyfrec.test@yahoo.com",
    "customFields": {},
    "dkuGit": {
      "gitReference": {
        "checkout": "main",
        "isDirty": false,
        "lastHash": "54ccce147b1bce4550fb8ce10ee8e7151284097b",
        "lastTimestamp": 1674152512000,
        "remote": "https://github.com/tylerfreckmann/coder_handson.git",
        "remotePath": "notebooks/Custom Modeling.ipynb"
      },
      "lastInteraction": 1674157674153
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "modifiedBy": "tyler.freckmann@dataiku.com",
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
